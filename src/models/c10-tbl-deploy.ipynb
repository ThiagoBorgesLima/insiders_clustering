{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA005: High Value Customer Indentification ( Insiders )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sqlite3\n",
    "import s3fs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import umap.umap_ as umap\n",
    "import boto3\n",
    "from sklearn import cluster as c\n",
    "from sklearn import metrics as m\n",
    "from sklearn import mixture as mx\n",
    "from sklearn import manifold as mn \n",
    "from sklearn import ensemble as en\n",
    "from sklearn import decomposition as dd\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "from plotly import express as px\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from scipy.cluster import hierarchy as hc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# path local = /Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/\n",
    "# path_s3 = 's3://insiders-dataset-tbl/'\n",
    "# df_raw = pd.read_csv( path_s3 + 'ecommerce.csv' )\n",
    "\n",
    "# # drop extra column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id='AKIAW44IREBLQIPGP37Y',\n",
    "    aws_secret_access_key='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',\n",
    "    )\n",
    "#banco comunidadeds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_S3_BUCKET = \"insiders-dataset-tbl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the low level functional client\n",
    "client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIAW44IREBLQIPGP37Y',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'us-east-1'\n",
    ")\n",
    "    \n",
    "# Creating the high level object oriented interface\n",
    "resource = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id = 'AKIAW44IREBLQIPGP37Y',\n",
    "    aws_secret_access_key = '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',\n",
    "    region_name = 'us-east-1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing bucket names...\n",
      "Bucket Name: insiders-dataset-tbl\n",
      "Bucket Name: insiders-dataset-tbl-2\n"
     ]
    }
   ],
   "source": [
    "# Fetch the list of existing buckets\n",
    "clientResponse = client.list_buckets()\n",
    "    \n",
    "# Print the bucket names one by one\n",
    "print('Printing bucket names...')\n",
    "for bucket in clientResponse['Buckets']:\n",
    "    print(f'Bucket Name: {bucket[\"Name\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa3 in position 28: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1072\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1222\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1235\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1431\u001b[0m, in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa3 in position 28: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m obj \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mget_object(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     Bucket \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39minsiders-dataset-tbl\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Key \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mecommerce.csv\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Read data from the S3 object\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(obj[\u001b[39m'\u001b[39;49m\u001b[39mBody\u001b[39;49m\u001b[39m'\u001b[39;49m], encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39miso-8859-1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:581\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n\u001b[1;32m    580\u001b[0m \u001b[39mwith\u001b[39;00m parser:\n\u001b[0;32m--> 581\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\u001b[39m.\u001b[39;49mread(nrows)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1253\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1251\u001b[0m nrows \u001b[39m=\u001b[39m validate_integer(\u001b[39m\"\u001b[39m\u001b[39mnrows\u001b[39m\u001b[39m\"\u001b[39m, nrows)\n\u001b[1;32m   1252\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1253\u001b[0m     index, columns, col_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mread(nrows)\n\u001b[1;32m   1254\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1255\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:225\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    224\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlow_memory:\n\u001b[0;32m--> 225\u001b[0m         chunks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reader\u001b[39m.\u001b[39;49mread_low_memory(nrows)\n\u001b[1;32m    226\u001b[0m         \u001b[39m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    227\u001b[0m         data \u001b[39m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:805\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:883\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1026\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1079\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1222\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1235\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1431\u001b[0m, in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa3 in position 28: invalid start byte"
     ]
    }
   ],
   "source": [
    "# Create the S3 object\n",
    "obj = client.get_object(\n",
    "    Bucket = 'insiders-dataset-tbl',\n",
    "    Key = 'ecommerce.csv',\n",
    "    \n",
    ")\n",
    "    \n",
    "# Read data from the S3 object\n",
    "data = pd.read_csv(obj['Body'], encoding='iso-8859-1')\n",
    "    \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "insiders-dataset-tbl/ecommerce.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df_raw \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39ms3://\u001b[39;49m\u001b[39m{\u001b[39;49;00mAWS_S3_BUCKET\u001b[39m}\u001b[39;49;00m\u001b[39m/ecommerce.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, encoding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39miso-8859-1\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         storage_options\u001b[39m=\u001b[39;49m{\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mkey\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mAKIAW44IREBLQIPGP37Y\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39msecret\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mCMMloVRsPDtHU28TML5kt4Jkb7FYbh13FjoL2fxB\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         }\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m )\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/thiago/Thiago/Data_Science/comunidade_ds/insiders_clustering/src/models/c10-tbl-deploy.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df_raw\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/common.py:667\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    664\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[1;32m    666\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[0;32m--> 667\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[1;32m    668\u001b[0m     path_or_buf,\n\u001b[1;32m    669\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    670\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    671\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    672\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    673\u001b[0m )\n\u001b[1;32m    675\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[1;32m    676\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/pandas/io/common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m     file_obj \u001b[39m=\u001b[39m fsspec\u001b[39m.\u001b[39;49mopen(\n\u001b[1;32m    383\u001b[0m         filepath_or_buffer, mode\u001b[39m=\u001b[39;49mfsspec_mode, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m(storage_options \u001b[39mor\u001b[39;49;00m {})\n\u001b[0;32m--> 384\u001b[0m     )\u001b[39m.\u001b[39;49mopen()\n\u001b[1;32m    385\u001b[0m \u001b[39m# GH 34626 Reads from Public Buckets without Credentials needs anon=True\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mtuple\u001b[39m(err_types_to_retry_with_anon):\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/core.py:135\u001b[0m, in \u001b[0;36mOpenFile.open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    129\u001b[0m     \u001b[39m\"\"\"Materialise this as a real open file without context\u001b[39;00m\n\u001b[1;32m    130\u001b[0m \n\u001b[1;32m    131\u001b[0m \u001b[39m    The OpenFile object should be explicitly closed to avoid enclosed file\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[39m    instances persisting. You must, therefore, keep a reference to the OpenFile\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[39m    during the life of the file-like it generates.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__enter__\u001b[39;49m()\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/core.py:103\u001b[0m, in \u001b[0;36mOpenFile.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__enter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    101\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 103\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49mopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath, mode\u001b[39m=\u001b[39;49mmode)\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfobjects \u001b[39m=\u001b[39m [f]\n\u001b[1;32m    107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/spec.py:1106\u001b[0m, in \u001b[0;36mAbstractFileSystem.open\u001b[0;34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     ac \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mautocommit\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_intrans)\n\u001b[0;32m-> 1106\u001b[0m     f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_open(\n\u001b[1;32m   1107\u001b[0m         path,\n\u001b[1;32m   1108\u001b[0m         mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   1109\u001b[0m         block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m   1110\u001b[0m         autocommit\u001b[39m=\u001b[39;49mac,\n\u001b[1;32m   1111\u001b[0m         cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1112\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1113\u001b[0m     )\n\u001b[1;32m   1114\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1115\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39mfsspec\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompression\u001b[39;00m \u001b[39mimport\u001b[39;00m compr\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/s3fs/core.py:640\u001b[0m, in \u001b[0;36mS3FileSystem._open\u001b[0;34m(self, path, mode, block_size, acl, version_id, fill_cache, cache_type, autocommit, requester_pays, cache_options, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[39mif\u001b[39;00m cache_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    638\u001b[0m     cache_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_cache_type\n\u001b[0;32m--> 640\u001b[0m \u001b[39mreturn\u001b[39;00m S3File(\n\u001b[1;32m    641\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    642\u001b[0m     path,\n\u001b[1;32m    643\u001b[0m     mode,\n\u001b[1;32m    644\u001b[0m     block_size\u001b[39m=\u001b[39;49mblock_size,\n\u001b[1;32m    645\u001b[0m     acl\u001b[39m=\u001b[39;49macl,\n\u001b[1;32m    646\u001b[0m     version_id\u001b[39m=\u001b[39;49mversion_id,\n\u001b[1;32m    647\u001b[0m     fill_cache\u001b[39m=\u001b[39;49mfill_cache,\n\u001b[1;32m    648\u001b[0m     s3_additional_kwargs\u001b[39m=\u001b[39;49mkw,\n\u001b[1;32m    649\u001b[0m     cache_type\u001b[39m=\u001b[39;49mcache_type,\n\u001b[1;32m    650\u001b[0m     autocommit\u001b[39m=\u001b[39;49mautocommit,\n\u001b[1;32m    651\u001b[0m     requester_pays\u001b[39m=\u001b[39;49mrequester_pays,\n\u001b[1;32m    652\u001b[0m     cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m    653\u001b[0m )\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/s3fs/core.py:1989\u001b[0m, in \u001b[0;36mS3File.__init__\u001b[0;34m(self, s3, path, mode, block_size, acl, version_id, fill_cache, s3_additional_kwargs, autocommit, cache_type, requester_pays, cache_options)\u001b[0m\n\u001b[1;32m   1987\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetails \u001b[39m=\u001b[39m s3\u001b[39m.\u001b[39minfo(path)\n\u001b[1;32m   1988\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mversion_id \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdetails\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mVersionId\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1989\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m   1990\u001b[0m     s3,\n\u001b[1;32m   1991\u001b[0m     path,\n\u001b[1;32m   1992\u001b[0m     mode,\n\u001b[1;32m   1993\u001b[0m     block_size,\n\u001b[1;32m   1994\u001b[0m     autocommit\u001b[39m=\u001b[39;49mautocommit,\n\u001b[1;32m   1995\u001b[0m     cache_type\u001b[39m=\u001b[39;49mcache_type,\n\u001b[1;32m   1996\u001b[0m     cache_options\u001b[39m=\u001b[39;49mcache_options,\n\u001b[1;32m   1997\u001b[0m )\n\u001b[1;32m   1998\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39ms3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfs  \u001b[39m# compatibility\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[39m# when not using autocommit we want to have transactional state to manage\u001b[39;00m\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/spec.py:1462\u001b[0m, in \u001b[0;36mAbstractBufferedFile.__init__\u001b[0;34m(self, fs, path, mode, block_size, autocommit, cache_type, cache_options, size, **kwargs)\u001b[0m\n\u001b[1;32m   1460\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m size\n\u001b[1;32m   1461\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1462\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdetails[\u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcache \u001b[39m=\u001b[39m caches[cache_type](\n\u001b[1;32m   1464\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocksize, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetch_range, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcache_options\n\u001b[1;32m   1465\u001b[0m     )\n\u001b[1;32m   1466\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/spec.py:1475\u001b[0m, in \u001b[0;36mAbstractBufferedFile.details\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1472\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[1;32m   1473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdetails\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1474\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1475\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfs\u001b[39m.\u001b[39;49minfo(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath)\n\u001b[1;32m   1476\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_details\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/asyn.py:113\u001b[0m, in \u001b[0;36msync_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    112\u001b[0m     \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m obj \u001b[39mor\u001b[39;00m args[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m sync(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloop, func, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/asyn.py:98\u001b[0m, in \u001b[0;36msync\u001b[0;34m(loop, func, timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[39mraise\u001b[39;00m FSTimeoutError \u001b[39mfrom\u001b[39;00m \u001b[39mreturn_result\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(return_result, \u001b[39mBaseException\u001b[39;00m):\n\u001b[0;32m---> 98\u001b[0m     \u001b[39mraise\u001b[39;00m return_result\n\u001b[1;32m     99\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     \u001b[39mreturn\u001b[39;00m return_result\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/fsspec/asyn.py:53\u001b[0m, in \u001b[0;36m_runner\u001b[0;34m(event, coro, result, timeout)\u001b[0m\n\u001b[1;32m     51\u001b[0m     coro \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mwait_for(coro, timeout\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 53\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m coro\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m ex:\n\u001b[1;32m     55\u001b[0m     result[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m ex\n",
      "File \u001b[0;32m~/Thiago/Data_Science/comunidade_ds/insiders_clustering/ins_clustenv/lib/python3.10/site-packages/s3fs/core.py:1257\u001b[0m, in \u001b[0;36mS3FileSystem._info\u001b[0;34m(self, path, bucket, key, refresh, version_id)\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1246\u001b[0m         out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mKeyCount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   1247\u001b[0m         \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContents\u001b[39m\u001b[39m\"\u001b[39m, [])\n\u001b[1;32m   1248\u001b[0m         \u001b[39mor\u001b[39;00m out\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mCommonPrefixes\u001b[39m\u001b[39m\"\u001b[39m, [])\n\u001b[1;32m   1249\u001b[0m     ):\n\u001b[1;32m   1250\u001b[0m         \u001b[39mreturn\u001b[39;00m {\n\u001b[1;32m   1251\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([bucket, key]),\n\u001b[1;32m   1252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mdirectory\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1253\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39msize\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m,\n\u001b[1;32m   1254\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mStorageClass\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDIRECTORY\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1255\u001b[0m         }\n\u001b[0;32m-> 1257\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(path)\n\u001b[1;32m   1258\u001b[0m \u001b[39mexcept\u001b[39;00m ClientError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1259\u001b[0m     \u001b[39mraise\u001b[39;00m translate_boto_error(e, set_cause\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: insiders-dataset-tbl/ecommerce.csv"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(f\"s3://{AWS_S3_BUCKET}/ecommerce.csv\", encoding='iso-8859-1',\n",
    "        storage_options={\n",
    "        \"key\": 'AKIAW44IREBLQIPGP37Y',\n",
    "        \"secret\": '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',\n",
    "        }\n",
    ")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 1.0. Descrição dos Dados </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = df_raw.drop( columns=['Unnamed: 8'], axis=1 )\n",
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_new = [ 'invoice_no', 'stock_code', 'description', 'quantity', 'invoice_date',\n",
    "       'unit_price', 'customer_id', 'country' ]\n",
    "df1.columns = cols_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Number of rows: {}'.format( df1.shape[0] ) )\n",
    "print( 'Number of cols: {}'.format( df1.shape[1] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Replace NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing = df1.loc[df1['customer_id'].isna(), :]\n",
    "df_not_missing = df1.loc[~df1['customer_id'].isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create reference\n",
    "df_backup = pd.DataFrame( df_missing['invoice_no'].drop_duplicates() )\n",
    "df_backup['customer_id'] = np.arange( 19000, 19000+len( df_backup ), 1)\n",
    "\n",
    "# merge original with reference dataframe\n",
    "df1 = pd.merge( df1, df_backup, on='invoice_no', how='left' )\n",
    "\n",
    "# coalesce\n",
    "df1['customer_id'] = df1['customer_id_x'].combine_first( df1['customer_id_y'] )\n",
    "\n",
    "# drop extra columns\n",
    "df1 = df1.drop( columns=['customer_id_x', 'customer_id_y'], axis=1 )\n",
    "\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Change Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invoice_date\n",
    "df1['invoice_date'] = pd.to_datetime( df1['invoice_date'], format='%d-%b-%y' )\n",
    "\n",
    "# customer_id\n",
    "df1['customer_id'] = df1['customer_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_attributes = df1.select_dtypes( include=['int64', 'float64'] )\n",
    "cat_attributes = df1.select_dtypes( exclude=['int64', 'float64', 'datetime64[ns]'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.1. Numerical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# central tendency - mean, median\n",
    "ct1 = pd.DataFrame( num_attributes.apply( np.mean ) ).T\n",
    "ct2 = pd.DataFrame( num_attributes.apply( np.median ) ).T\n",
    "\n",
    "# dispersion - desvio padrão, mínimo, máximo, range, skew, kurtosis\n",
    "d1 = pd.DataFrame( num_attributes.apply( np.std ) ).T\n",
    "d2 = pd.DataFrame( num_attributes.apply( np.min ) ).T\n",
    "d3 = pd.DataFrame( num_attributes.apply( np.max ) ).T\n",
    "d4 = pd.DataFrame( num_attributes.apply( lambda x: x.max() - x.min() ) ).T\n",
    "d5 = pd.DataFrame( num_attributes.apply( lambda x: x.skew() ) ).T\n",
    "d6 = pd.DataFrame( num_attributes.apply( lambda x: x.kurtosis() ) ).T\n",
    "\n",
    "# concatenate\n",
    "m1 = pd.concat( [d2, d3, d4, ct1, ct2, d1, d5, d6] ).T.reset_index()\n",
    "m1.columns = ['attributes', 'min', 'max', 'range', 'mean', 'mediana', 'std', 'skew', 'kurtosis']\n",
    "m1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7.2. Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Invoice No</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# problema: Temos o invoice com letras e numeros\n",
    "#df1['invoice_no'].astype( int )\n",
    "\n",
    "# Identificação\n",
    "df_letter_invoices = df1.loc[df1['invoice_no'].apply( lambda x: bool ( re.search( '[^0-9]+', x ) ) ), :]\n",
    "df_letter_invoices.head()\n",
    "\n",
    "print( 'Total number os invoices: {}'.format( len ( df_letter_invoices ) ) ) \n",
    "print( 'Total number os negative quantity: {}'.format( len( df_letter_invoices[df_letter_invoices['quantity'] < 0 ] ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_attributes['invoice_no'].astype( int )\n",
    "len( cat_attributes.loc[ cat_attributes['invoice_no'].apply( lambda x: bool( re.search( '[^0-9]+', x ) ) ), 'invoice_no'].drop_duplicates() )\n",
    "#cat_attributes.loc[173995, : ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Stock Code</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock code\n",
    "#at_least_one_string = cat_attributes.loc[ cat_attributes['stock_code'].apply( lambda x: bool ( re.search( '[^0-9+]', x ) ) ), 'stock_code'].head()\n",
    "\n",
    "#print( at_least_one_string )\n",
    "\n",
    "#\n",
    "#cat_attributes.loc[cat_attributes['stock_code'].apply( lambda x: bool( re.search( '^[a-zA-Z]+$', x ) ) ), 'stock_code'].unique() \n",
    "df1.loc[cat_attributes['stock_code'].apply( lambda x: bool( re.search( '^[a-zA-Z]+$', x ) ) ), :].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check stock codes only characters\n",
    "df1.loc[df1['stock_code'].apply( lambda x: bool ( re.search( '^[a-zA-Z]+$', x ) ) ), 'stock_code'].unique()\n",
    "\n",
    "# Ação:\n",
    "## 1. Remove stock_code in ['POST', 'D', 'M', 'PADS', 'DOT', 'CRUK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 2.0. Filtragem das Variáveis </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Numerical Attributes ======\n",
    "# unit price > 0.04\n",
    "df2 = df2.loc[df2['unit_price'] > 0.04, :]\n",
    "\n",
    "# ===== Categorical Attributes ======\n",
    "# stock code != [ POST, D, M, DOT, CRUK ]\n",
    "df2 = df2[~df2['stock_code'].isin( ['POST', 'D', 'DOT', 'M', 'S', 'AMAZONFEE', 'm', 'DCGSSBOY',\n",
    "       'DCGSSGIRL', 'PADS', 'B', 'CRUK']) ] \n",
    "\n",
    "# description\n",
    "df2 = df2.drop( columns='description', axis=1 )\n",
    "\n",
    "# map\n",
    "df2 = df2[~df2['country'].isin( ['European Community', 'Unspecified'] ) ]\n",
    "\n",
    "# bad users\n",
    "df2 = df2[~df2['customer_id'].isin( [16446] ) ] \n",
    "\n",
    "## quantity - Negative numbers means product returns\n",
    "df2_returns = df2.loc[df2['quantity'] < 0, :]\n",
    "df2_purchase = df2.loc[df2['quantity'] >= 0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 3.0. Feature Engineering </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reference\n",
    "df_ref = df3.drop( ['invoice_no', 'stock_code','quantity', 'invoice_date', 'unit_price', 'country' ], axis=1 ).drop_duplicates( ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1. Gross Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gross Revenue ( Faturamento ) quantity * price\n",
    "df2_purchase.loc[:, 'gross_revenue'] = df2_purchase.loc[:, 'quantity'] * df2_purchase.loc[:, 'unit_price']\n",
    "\n",
    "# Monetary\n",
    "df_monetary = df2_purchase.loc[:, ['customer_id', 'gross_revenue']].groupby( 'customer_id').sum().reset_index()\n",
    "df_ref = pd.merge( df_ref, df_monetary, how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2. Recency - Day from last Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recency - It depends on product returns\n",
    "df_recency = df2_purchase.loc[:, ['customer_id', 'invoice_date']].groupby( 'customer_id' ).max().reset_index()\n",
    "df_recency['recency_days'] = ( df2_purchase['invoice_date'].max() - df_recency['invoice_date'] ).dt.days\n",
    "df_recency = df_recency[['customer_id', 'recency_days']].copy()\n",
    "df_ref = pd.merge( df_ref, df_recency, how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.3. Quantity of Products Purchased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de Produtos - It depends os product returns\n",
    "df_frequency = (df2_purchase.loc[:, ['customer_id', 'stock_code']].groupby( 'customer_id' )\n",
    "                                                                .count()\n",
    "                                                                .reset_index()\n",
    "                                                                .rename( columns={'stock_code':'qtde_products'} ))\n",
    "df_ref = pd.merge( df_ref, df_frequency, how='left', on='customer_id' )\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.4. Frequency Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aux = ( df2_purchase[['customer_id', 'invoice_no', 'invoice_date']].drop_duplicates()\n",
    "                                                    .groupby( 'customer_id' )\n",
    "                                                    .agg( max_ = ( 'invoice_date', 'max' ),\n",
    "                                                          min_ = ( 'invoice_date', 'min' ),\n",
    "                                                         days_ = ( 'invoice_date', lambda x: ( ( x.max() - x.min() ).days ) + 1 ),\n",
    "                                                          buy_ = ( 'invoice_no', 'count' ) ) ).reset_index()\n",
    "\n",
    "# Frequency\n",
    "df_aux['frequency'] = df_aux[[ 'buy_', 'days_']].apply( lambda x: x['buy_'] / x['days_'] if x['days_'] != 0 else 0, axis=1)\n",
    "\n",
    "# Merge\n",
    "df_ref = pd.merge( df_ref, df_aux[['customer_id', 'frequency']], on='customer_id', how='left' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.5. Number os Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Returns\n",
    "df_returns = df2_returns[['customer_id', 'quantity']].groupby( 'customer_id' ).sum().reset_index().rename( columns={'quantity':'qtde_returns'} )\n",
    "df_returns['qtde_returns'] = df_returns['qtde_returns'] * -1\n",
    "\n",
    "df_ref = pd.merge( df_ref, df_returns, how='left', on='customer_id' )\n",
    "df_ref.loc[df_ref['qtde_returns'].isna(), 'qtde_returns'] = 0\n",
    "\n",
    "df_ref.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 4.0. EDA ( Exploratory Data Analysis )</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df_ref.dropna()\n",
    "df4.isna().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Estudo do Espaço"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected dataset\n",
    "cols_selected = ['customer_id', 'gross_revenue', 'recency_days', 'qtde_products', 'frequency', 'qtde_returns']\n",
    "df43 = df4[ cols_selected ].drop( columns='customer_id', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df43.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = pp.MinMaxScaler()\n",
    "\n",
    "df43['gross_revenue'] = mm.fit_transform( df43[['gross_revenue']] )\n",
    "df43['recency_days'] = mm.fit_transform( df43[['recency_days']] )\n",
    "df43['qtde_products'] = mm.fit_transform( df43[['qtde_products']] )\n",
    "df43['frequency'] = mm.fit_transform( df43[['frequency']] )\n",
    "df43['qtde_returns'] = mm.fit_transform( df43[['qtde_returns']] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3. Tree-Based Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "X = df43.drop( columns=['gross_revenue'], axis=1 )\n",
    "y = df43['gross_revenue']\n",
    "\n",
    "# model definition\n",
    "rf_model = en.RandomForestRegressor( n_estimators=100, random_state=42 )\n",
    "\n",
    "# model training\n",
    "rf_model.fit( X, y )\n",
    "\n",
    "# Leaf\n",
    "df_leaf = pd.DataFrame( rf_model.apply( X ) )\n",
    "\n",
    "# dataframe Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduzer dimensionality\n",
    "reducer = umap.UMAP( random_state=42 )\n",
    "embedding = reducer.fit_transform( df_leaf )\n",
    "\n",
    "# embedding\n",
    "df_tree = pd.DataFrame()\n",
    "df_tree['embedding_x'] = embedding[:, 0]\n",
    "df_tree['embedding_y'] = embedding[:, 1]\n",
    "\n",
    "sns.scatterplot( x='embedding_x',\n",
    "                 y='embedding_y',\n",
    "                 data=df_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 5.0. Data Preparation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 6.0. Model Training </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition GMM\n",
    "k = 23\n",
    "gmm_model = mx.GaussianMixture( n_components=k, n_init=300, random_state = 42 )\n",
    "\n",
    "# model training\n",
    "gmm_model.fit( X )\n",
    "\n",
    "# model predict\n",
    "labels = gmm_model.predict( X )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Cluster Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SS ( Silhouette Score )\n",
    "print ( 'SS value: {}'.format( m.silhouette_score( X, labels, metric='euclidean' ) ) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 7.0. Cluster Analysis </font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1. Cluster Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df92 = df4[ cols_selected ].copy()\n",
    "df92['cluster'] = labels\n",
    "\n",
    "# change dtypes\n",
    "df92['recency_days'] = df92['recency_days'].astype( int )\n",
    "df92['qtde_products'] = df92['qtde_products'].astype( int )\n",
    "df92['qtde_returns'] = df92['qtde_returns'].astype( int )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Customer\n",
    "df_cluster = df92[['customer_id', 'cluster']].groupby('cluster').count().reset_index()\n",
    "df_cluster['perc_cluster'] = 100 * ( df_cluster['customer_id'] / df_cluster['customer_id'].sum() )\n",
    "\n",
    "# Average Gross Revenue\n",
    "df_avg_gross_revenue = df92[['gross_revenue', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_avg_gross_revenue, how='inner', on='cluster')\n",
    "\n",
    "# Average Recency Days\n",
    "df_avg_recency_days = df92[['recency_days', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_avg_recency_days, how='inner', on='cluster')\n",
    "\n",
    "# Average Invoice_no\n",
    "df_qtde_products = df92[['qtde_products', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_qtde_products, how='inner', on='cluster')\n",
    "\n",
    "# Frequency\n",
    "df_frequency = df92[['frequency', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_frequency, how='inner', on='cluster')\n",
    "\n",
    "# Returns\n",
    "df_qtde_returns = df92[['qtde_returns', 'cluster']].groupby('cluster').mean().reset_index()\n",
    "df_cluster = pd.merge( df_cluster, df_qtde_returns, how='inner', on='cluster')\n",
    "\n",
    "df_cluster.sort_values(by='gross_revenue', ascending=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0   Cluster Insiders\n",
    "\n",
    "14/2 Clusters Quase Insiders\n",
    "\n",
    "2  Cluster Precisa de Mais Valor \"Expend Money\"\n",
    "\n",
    "16   Cluster Mais valor / Frequencia\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Insiders: ( Cluster 0 )\n",
    "    - Número de customers: 373 ( 12,5% dos customers )\n",
    "    - Faturamento médio: 10500\n",
    "    - Recência em média: 19 dias\n",
    "    - Média de produtos comprados: 475 produtos\n",
    "    - Frequência de produtos comprados: 0,11 produtos/dia\n",
    "\n",
    "### Cluster 02:\n",
    "    - Número de customers: 31 ( 71% dos customers )\n",
    "    - Recência em média: 14 dias\n",
    "    - Compras em média: 53 compras\n",
    "    - Receita em média: $40.543,52\n",
    "\n",
    "### Cluster 03:\n",
    "    - Número de customers: 4335 ( 99% dos customers )\n",
    "    - Recência em média: 92 dias\n",
    "    - Compras em média: 5 compras\n",
    "    - Receita em média: $1.372,57"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> 8.0 Deploy To Production </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df92.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df92.dtypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Inserto into SQLITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df92['recency_days'] = df92['recency_days'].astype( int )\n",
    "df92['qtde_products'] = df92['qtde_products'].astype( int )\n",
    "df92['qtde_returns'] = df92['qtde_returns'].astype( int )\n",
    "\n",
    "#df92['last_training_timestamp'] = datetime.now().strftime( '%Y-%m-%d %H:%M%S' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database conection\n",
    "\n",
    "#endpoint = 'sqlite:///insiders_db.sqlite'\n",
    "host='database-insiders-test.cupfsfkbeh2a.us-east-1.rds.amazonaws.com'\n",
    "port='5432'\n",
    "database='postgres' \n",
    "user='thiago'\n",
    "pwd='comunidadeds!'\n",
    "\n",
    "endpoint='postgresql://thiago:comunidadeds!@database-insiders-test.cupfsfkbeh2a.us-east-1.rds.amazonaws.com/postgres'\n",
    "\n",
    "conn = create_engine( endpoint )\n",
    "\n",
    "# # drop table\n",
    "# query_drop_insiders = \"\"\"\n",
    "#     DROP TABLE insiders\n",
    "# \"\"\"\n",
    "\n",
    "# create table\n",
    "# query_create_insiders = \"\"\"\n",
    "#     CREATE TABLE insiders (\n",
    "#         customer_id     INTEGER,\n",
    "#         gross_revenue   REAL,\n",
    "#         recency_days    INTEGER,\n",
    "#         qtde_products   INTEGER,\n",
    "#         frequency       REAL,\n",
    "#         qtde_returns    INTEGER,\n",
    "#         cluster         INTEGER\n",
    "#     )\n",
    "# \"\"\"    \n",
    "\n",
    "# #conn = sqlite3.connect( 'insiders_db.sqlite')\n",
    "\n",
    "# conn.execute( query_create_insiders )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # insert data\n",
    "df92.to_sql( 'insiders', con=conn, if_exists='append', index=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # consulting database / get query\n",
    "# query_collect = \"\"\"\n",
    "#     SELECT * FROM insiders\n",
    "# \"\"\"\n",
    "\n",
    "# df = pd.read_sql_query( query_collect, conn )\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ins_clustenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (v3.10.4:9d38120e33, Mar 23 2022, 17:29:05) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f0fdcbedca795ffb30cc6c2d55028e9ca1e3226a02df4c6465ca0b02399e4bfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
